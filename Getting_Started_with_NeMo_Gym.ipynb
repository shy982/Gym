{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üèãÔ∏è Getting Started with NeMo Gym\n",
        "\n",
        "**A Complete Step-by-Step Guide for Newcomers**\n",
        "\n",
        "> üí° **Tip:** Run this notebook from within the cloned `Gym` directory. NeMo Gym will be installed automatically when you run the setup cells.\n",
        "\n",
        "---\n",
        "\n",
        "NeMo Gym is a library for building reinforcement learning (RL) training environments for large language models (LLMs). It provides infrastructure to develop environments, scale rollout collection, and integrate seamlessly with your preferred training framework.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "This notebook covers:\n",
        "\n",
        "1. **üîß Environment Setup** - Install NeMo Gym and configure NVIDIA API keys\n",
        "2. **üöÄ Quick Start** - Start servers and interact with your first agent (powered by [Nemotron Super NIM](https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1))\n",
        "3. **üìä Rollout Collection** - Generate verified training data\n",
        "4. **üè¢ Workplace Assistant Tutorial** - Explore multi-step tool calling\n",
        "5. **üí™ Training with RL** - Understand GPU requirements and training options\n",
        "\n",
        "---\n",
        "\n",
        "## üíª Hardware & GPU Requirements\n",
        "\n",
        "| Component | NeMo Gym Library | RL Training (Optional) |\n",
        "|-----------|------------------|------------------------|\n",
        "| **GPU** | ‚ùå Not required | ‚úÖ Required |\n",
        "| **CPU** | Any modern x86_64 or ARM64 | Any modern x86_64 |\n",
        "| **RAM** | 8 GB minimum (16 GB+ recommended) | 64 GB+ per node |\n",
        "| **Storage** | 2-5 GB | 100 GB+ (shared filesystem) |\n",
        "\n",
        "### Training GPU Requirements\n",
        "\n",
        "| Training Framework | GPU Requirements |\n",
        "|-------------------|------------------|\n",
        "| **Unsloth (Colab)** | 1√ó T4 GPU (16GB VRAM) - Free tier available |\n",
        "| **Unsloth (Local)** | 1√ó GPU with 16GB+ VRAM |\n",
        "| **NeMo RL (Single-node)** | 8√ó NVIDIA GPUs (80GB+ each, e.g., H100/A100) |\n",
        "| **NeMo RL (Multi-node)** | 8+ nodes √ó 8 GPUs (80GB+ each) |\n",
        "\n",
        "**Note:** This notebook focuses on NeMo Gym setup and exploration, which does NOT require a GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 1: Environment Setup\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Before starting, ensure you have:\n",
        "- **Git** installed\n",
        "- **Python 3.12+** installed\n",
        "- **NVIDIA API key** from [NVIDIA Build](https://build.nvidia.com/) (free tier available)\n",
        "\n",
        "## Step 1.1: Verify Python Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "print(f\"Python version: {sys.version}\")\n",
        "major, minor = sys.version_info[:2]\n",
        "\n",
        "if major >= 3 and minor >= 12:\n",
        "    print(\"‚úÖ Python version is compatible (3.12+)\")\n",
        "else:\n",
        "    print(\"‚ùå Please upgrade to Python 3.12 or higher\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.2: Clone the Repository (If Not Already Done)\n",
        "\n",
        "If you're running this notebook outside the Gym repository, clone it first:\n",
        "\n",
        "```bash\n",
        "git clone git@github.com:NVIDIA-NeMo/Gym.git\n",
        "cd Gym\n",
        "```\n",
        "\n",
        "Then open this notebook from inside the `Gym` directory.\n",
        "\n",
        "## Step 1.3: Install & Verify NeMo Gym\n",
        "\n",
        "Run the cell below to automatically install NeMo Gym if needed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "def ensure_pip():\n",
        "    \"\"\"Ensure pip is available in the current Python environment.\"\"\"\n",
        "    result = subprocess.run(\n",
        "        [sys.executable, \"-m\", \"pip\", \"--version\"],\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "    if result.returncode != 0:\n",
        "        print(\"üì¶ Installing pip...\")\n",
        "        subprocess.run([sys.executable, \"-m\", \"ensurepip\", \"--upgrade\"], \n",
        "                      capture_output=True)\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"],\n",
        "                      capture_output=True)\n",
        "\n",
        "def run_pip(*args):\n",
        "    \"\"\"Run pip command and return success status.\"\"\"\n",
        "    result = subprocess.run(\n",
        "        [sys.executable, \"-m\", \"pip\", *args],\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "    return result.returncode == 0, result.stderr\n",
        "\n",
        "def clean_install_nemo_gym():\n",
        "    \"\"\"Uninstall and reinstall NeMo Gym from scratch.\"\"\"\n",
        "    \n",
        "    # Step 0: Ensure pip is available\n",
        "    ensure_pip()\n",
        "    \n",
        "    # Step 1: Uninstall existing nemo_gym if present\n",
        "    print(\"üßπ Uninstalling existing NeMo Gym (if any)...\")\n",
        "    run_pip(\"uninstall\", \"nemo-gym\", \"-y\")\n",
        "    run_pip(\"uninstall\", \"nemo_gym\", \"-y\")\n",
        "    \n",
        "    # Clear any cached imports\n",
        "    mods_to_remove = [k for k in sys.modules if k.startswith('nemo_gym')]\n",
        "    for mod in mods_to_remove:\n",
        "        del sys.modules[mod]\n",
        "    \n",
        "    # Step 2: Install fresh from source\n",
        "    print(\"üì¶ Installing NeMo Gym from source... (this may take a minute)\")\n",
        "    success, err = run_pip(\"install\", \"-e\", \".\", \"--no-cache-dir\")\n",
        "    \n",
        "    if success:\n",
        "        print(\"‚úÖ NeMo Gym installed successfully!\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"‚ùå Installation failed: {err}\")\n",
        "        return False\n",
        "\n",
        "# Always do a clean install to ensure consistency\n",
        "print(\"üîÑ Setting up NeMo Gym (clean install)...\\n\")\n",
        "if clean_install_nemo_gym():\n",
        "    import nemo_gym\n",
        "    print(f\"\\n‚úÖ NeMo Gym is ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.4: Configure Your NVIDIA API Key\n",
        "\n",
        "Create an `env.yaml` file with your API credentials. This file keeps secrets out of version control.\n",
        "\n",
        "We'll use **NVIDIA's Nemotron Super NIM** - a powerful 49B parameter model optimized for reasoning, tool calling, and instruction following with 128K context length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Get the Gym project root directory\n",
        "# Adjust this path if running from a different location\n",
        "GYM_ROOT = Path(os.getcwd())\n",
        "if not (GYM_ROOT / \"nemo_gym\").exists():\n",
        "    # Try parent directory\n",
        "    GYM_ROOT = GYM_ROOT.parent\n",
        "    if not (GYM_ROOT / \"nemo_gym\").exists():\n",
        "        print(\"‚ö†Ô∏è  Cannot find Gym root directory. Please run this notebook from the Gym directory.\")\n",
        "\n",
        "ENV_YAML_PATH = GYM_ROOT / \"env.yaml\"\n",
        "print(f\"üìÅ Gym root directory: {GYM_ROOT}\")\n",
        "print(f\"üìÑ env.yaml path: {ENV_YAML_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if env.yaml already exists\n",
        "if ENV_YAML_PATH.exists():\n",
        "    print(\"‚úÖ env.yaml already exists\")\n",
        "    print(\"\\nCurrent content (API key masked):\")\n",
        "    content = ENV_YAML_PATH.read_text()\n",
        "    for line in content.split('\\n'):\n",
        "        if 'api_key' in line.lower():\n",
        "            key_part = line.split(':')[0]\n",
        "            print(f\"{key_part}: nvapi-****...****\")\n",
        "        else:\n",
        "            print(line)\n",
        "else:\n",
        "    print(\"‚ùå env.yaml not found. Please create it in the next step.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create or Update env.yaml\n",
        "\n",
        "**Option A:** Run the cell below and replace `nvapi-...` with your actual NVIDIA API key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚ö†Ô∏è REPLACE with your actual NVIDIA API key\n",
        "NVIDIA_API_KEY = \"nvapi-...\"  # <-- Replace this!\n",
        "POLICY_MODEL = \"nvidia/llama-3.3-nemotron-super-49b-v1\"  # Nemotron Super NIM\n",
        "\n",
        "if NVIDIA_API_KEY == \"nvapi-...\":\n",
        "    print(\"‚ö†Ô∏è  Please replace 'nvapi-...' with your actual NVIDIA API key\")\n",
        "    print(\"\\nYou can get your API key from: https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1\")\n",
        "else:\n",
        "    env_yaml_content = f\"\"\"policy_base_url: https://integrate.api.nvidia.com/v1\n",
        "policy_api_key: {NVIDIA_API_KEY}\n",
        "policy_model_name: {POLICY_MODEL}\n",
        "\"\"\"\n",
        "    \n",
        "    ENV_YAML_PATH.write_text(env_yaml_content)\n",
        "    print(\"‚úÖ env.yaml created successfully!\")\n",
        "    print(f\"üìç Location: {ENV_YAML_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Option B:** Create the file manually via terminal:\n",
        "\n",
        "```bash\n",
        "echo \"policy_base_url: https://integrate.api.nvidia.com/v1\n",
        "policy_api_key: nvapi-your-nvidia-api-key\n",
        "policy_model_name: nvidia/llama-3.3-nemotron-super-49b-v1\" > env.yaml\n",
        "```\n",
        "\n",
        "## Step 1.5: Validate API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate the API key before proceeding\n",
        "import requests\n",
        "\n",
        "try:\n",
        "    # Read config directly from env.yaml (no NeMo Gym dependencies needed)\n",
        "    # Simple parser that works without PyYAML\n",
        "    config = {}\n",
        "    with open(ENV_YAML_PATH, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line and ':' in line and not line.startswith('#'):\n",
        "                key, value = line.split(':', 1)\n",
        "                config[key.strip()] = value.strip()\n",
        "    \n",
        "    base_url = config['policy_base_url']\n",
        "    api_key = config['policy_api_key']\n",
        "    model_name = config['policy_model_name']\n",
        "    \n",
        "    # Test with a simple request using requests library\n",
        "    response = requests.post(\n",
        "        f\"{base_url}/chat/completions\",\n",
        "        headers={\n",
        "            \"Authorization\": f\"Bearer {api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        },\n",
        "        json={\n",
        "            \"model\": model_name,\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": \"Say hello\"}],\n",
        "            \"max_tokens\": 10\n",
        "        },\n",
        "        timeout=30\n",
        "    )\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        print(\"‚úÖ API key validated successfully!\")\n",
        "        print(f\"Model: {model_name}\")\n",
        "        print(f\"Response: {result['choices'][0]['message']['content']}\")\n",
        "    else:\n",
        "        print(f\"‚ùå API validation failed: {response.status_code}\")\n",
        "        print(f\"Response: {response.text}\")\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå env.yaml not found. Please create it in the previous step.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå API validation failed: {e}\")\n",
        "    print(\"\\nTroubleshooting:\")\n",
        "    print(\"- Check your NVIDIA API key is correct (should start with 'nvapi-')\")\n",
        "    print(\"- Get a free API key from: https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1\")\n",
        "    print(\"- Ensure env.yaml is in the Gym root directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 2: Quick Start - Your First Agent\n",
        "\n",
        "Now let's start the NeMo Gym servers and interact with an agent!\n",
        "\n",
        "## Understanding the Architecture\n",
        "\n",
        "NeMo Gym uses a server-based architecture:\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ   Head Server    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Agent Server    ‚îÇ\n",
        "‚îÇ   (port 11000)   ‚îÇ     ‚îÇ (auto-assigned)  ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                  ‚îÇ\n",
        "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚ñº                           ‚ñº\n",
        "           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "           ‚îÇ Model Server   ‚îÇ         ‚îÇResources Server‚îÇ\n",
        "           ‚îÇ (LLM Inference)‚îÇ         ‚îÇ (Tools/Verify) ‚îÇ\n",
        "           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "## Step 2.1: Start the Servers\n",
        "\n",
        "**‚ö†Ô∏è Important:** Run this in a **separate terminal** (not in this notebook):\n",
        "\n",
        "```bash\n",
        "# Navigate to Gym directory\n",
        "cd /path/to/Gym\n",
        "\n",
        "# Activate virtual environment (if using one)\n",
        "source .venv/bin/activate\n",
        "\n",
        "# Start servers (using vllm_model config for NVIDIA NIM API)\n",
        "config_paths=\"resources_servers/example_single_tool_call/configs/example_single_tool_call.yaml,\\\n",
        "responses_api_models/vllm_model/configs/vllm_model.yaml\"\n",
        "ng_run \"+config_paths=[${config_paths}]\"\n",
        "```\n",
        "\n",
        "> **Note:** The `vllm_model` config properly converts the Responses API to Chat Completions API format that NVIDIA NIM supports, and handles role mapping (e.g., \"developer\" ‚Üí \"system\").\n",
        "\n",
        "**Expected output:**\n",
        "```\n",
        "INFO:     Started server process [12345]\n",
        "INFO:     Uvicorn running on http://127.0.0.1:11000 (Press CTRL+C to quit)\n",
        "INFO:     Started server process [12346]  \n",
        "INFO:     Uvicorn running on http://127.0.0.1:62920 (Press CTRL+C to quit)\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.2: Wait for Servers and Verify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "def check_servers(max_attempts=10, delay=2):\n",
        "    \"\"\"Check if NeMo Gym servers are running.\"\"\"\n",
        "    for attempt in range(max_attempts):\n",
        "        try:\n",
        "            response = requests.get(\"http://localhost:11000/server_instances\", timeout=5)\n",
        "            if response.status_code == 200:\n",
        "                print(\"‚úÖ Servers are running!\")\n",
        "                print(\"\\nRegistered servers:\")\n",
        "                for server in response.json():\n",
        "                    print(f\"  - {server['name']}: {server['host']}:{server['port']}\")\n",
        "                return True\n",
        "        except requests.exceptions.ConnectionError:\n",
        "            print(f\"‚è≥ Waiting for servers... (attempt {attempt + 1}/{max_attempts})\")\n",
        "            time.sleep(delay)\n",
        "    \n",
        "    print(\"‚ùå Servers not responding. Please start them with ng_run.\")\n",
        "    return False\n",
        "\n",
        "# Check if servers are running\n",
        "servers_ok = check_servers()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.3: Interact with the Simple Agent\n",
        "\n",
        "If the servers are running, let's interact with the agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "if servers_ok:\n",
        "    print(\"ü§ñ Interacting with simple agent...\\n\")\n",
        "    \n",
        "    # Get the agent server URL from the head server\n",
        "    try:\n",
        "        instances = requests.get(\"http://localhost:11000/server_instances\").json()\n",
        "        agent_server = next(\n",
        "            (s for s in instances if \"simple_agent\" in s[\"name\"]), \n",
        "            None\n",
        "        )\n",
        "        \n",
        "        if not agent_server:\n",
        "            print(\"‚ùå Agent server not found. Make sure you started the correct config.\")\n",
        "        else:\n",
        "            agent_url = f\"http://{agent_server['host']}:{agent_server['port']}/v1/responses\"\n",
        "            \n",
        "            # Send request to the agent\n",
        "            # Note: Using 'system' role (not 'developer') for NVIDIA NIM compatibility\n",
        "            response = requests.post(\n",
        "                agent_url,\n",
        "                json={\n",
        "                    \"input\": [\n",
        "                        {\n",
        "                            \"role\": \"system\",\n",
        "                            \"content\": \"You are a helpful personal assistant.\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"role\": \"user\", \n",
        "                            \"content\": \"What's the weather in San Francisco?\"\n",
        "                        }\n",
        "                    ],\n",
        "                    \"tools\": [\n",
        "                        {\n",
        "                            \"type\": \"function\",\n",
        "                            \"name\": \"get_weather\",\n",
        "                            \"description\": \"Get weather for a city\",\n",
        "                            \"parameters\": {\n",
        "                                \"type\": \"object\",\n",
        "                                \"properties\": {\n",
        "                                    \"city\": {\"type\": \"string\", \"description\": \"City name\"}\n",
        "                                },\n",
        "                                \"required\": [\"city\"],\n",
        "                                \"additionalProperties\": False\n",
        "                            },\n",
        "                            \"strict\": True\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "                timeout=60\n",
        "            )\n",
        "            \n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                print(\"‚úÖ Agent interaction successful!\")\n",
        "                print(\"\\nüìã Response:\")\n",
        "                print(json.dumps(result, indent=2))\n",
        "            else:\n",
        "                print(f\"‚ùå Agent error: {response.status_code}\")\n",
        "                print(response.text)\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Please start the servers first (see Step 2.1)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What Just Happened?\n",
        "\n",
        "1. **User Query:** \"What's the weather in San Francisco?\"\n",
        "2. **Agent Action:** Called the `get_weather` tool with `{\"city\": \"San Francisco\"}`\n",
        "3. **Tool Response:** Returned weather data\n",
        "4. **Final Response:** Agent provided a natural language answer\n",
        "\n",
        "This demonstrates the core loop of NeMo Gym: **Query ‚Üí Tool Calls ‚Üí Verification ‚Üí Response**\n",
        "\n",
        "---\n",
        "\n",
        "# Part 3: Rollout Collection\n",
        "\n",
        "Rollouts are complete records of task executions with verification scores. They're the training data for RL!\n",
        "\n",
        "## Step 3.1: Inspect the Example Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "example_data_path = GYM_ROOT / \"resources_servers/example_single_tool_call/data/example.jsonl\"\n",
        "\n",
        "print(\"üìÑ Example dataset content:\\n\")\n",
        "\n",
        "with open(example_data_path, 'r') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= 2:  # Show first 2 examples\n",
        "            break\n",
        "        data = json.loads(line)\n",
        "        print(f\"Example {i+1}:\")\n",
        "        print(json.dumps(data, indent=2))\n",
        "        print(\"\\n\" + \"=\"*60 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3.2: Collect Rollouts\n",
        "\n",
        "Run this in your **second terminal** (with servers running in the first):\n",
        "\n",
        "```bash\n",
        "# Activate environment\n",
        "source .venv/bin/activate\n",
        "\n",
        "# Collect rollouts\n",
        "ng_collect_rollouts +agent_name=example_single_tool_call_simple_agent \\\n",
        "    +input_jsonl_fpath=resources_servers/example_single_tool_call/data/example.jsonl \\\n",
        "    +output_jsonl_fpath=results/example_single_tool_call_rollouts.jsonl \\\n",
        "    +limit=5 \\\n",
        "    +num_repeats=2 \\\n",
        "    +num_samples_in_parallel=3\n",
        "```\n",
        "\n",
        "### Parameters Explained:\n",
        "\n",
        "| Parameter | Description |\n",
        "|-----------|-------------|\n",
        "| `+agent_name` | Which agent to use |\n",
        "| `+input_jsonl_fpath` | Path to input dataset |\n",
        "| `+output_jsonl_fpath` | Path to save rollouts |\n",
        "| `+limit` | Max examples to process |\n",
        "| `+num_repeats` | Rollouts per example |\n",
        "| `+num_samples_in_parallel` | Concurrent requests |\n",
        "\n",
        "## Step 3.3: View Collected Rollouts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rollouts_path = GYM_ROOT / \"results/example_single_tool_call_rollouts.jsonl\"\n",
        "\n",
        "if rollouts_path.exists():\n",
        "    print(\"üìä Collected rollouts:\\n\")\n",
        "    \n",
        "    with open(rollouts_path, 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= 2:  # Show first 2 rollouts\n",
        "                break\n",
        "            rollout = json.loads(line)\n",
        "            print(f\"Rollout {i+1}:\")\n",
        "            print(f\"  Reward: {rollout.get('reward', 'N/A')}\")\n",
        "            print(f\"  Keys: {list(rollout.keys())}\")\n",
        "            print()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Rollouts file not found. Please run ng_collect_rollouts first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3.4: Launch the Rollout Viewer (Optional)\n",
        "\n",
        "For a visual interface to explore rollouts:\n",
        "\n",
        "```bash\n",
        "ng_viewer +jsonl_fpath=results/example_single_tool_call_rollouts.jsonl\n",
        "```\n",
        "\n",
        "Then visit: http://127.0.0.1:7860\n",
        "\n",
        "---\n",
        "\n",
        "# Part 4: Workplace Assistant Tutorial\n",
        "\n",
        "Now let's explore a more complex environment: **Workplace Assistant**. This is a multi-step agentic tool-use environment that tests a model's ability to execute business tasks.\n",
        "\n",
        "## About Workplace Assistant\n",
        "\n",
        "### Features:\n",
        "- **5 Databases:** Email, Calendar, Analytics, Project Management, CRM\n",
        "- **27 Tools:** Distributed across databases for various operations\n",
        "- **690+ Tasks:** Common business activities (emails, meetings, project management)\n",
        "- **Multi-step reasoning:** Tasks require 1-6 tool calls in sequence\n",
        "\n",
        "### Example Multi-Step Task:\n",
        "\n",
        "**User:** \"John is taking over all of Akira's leads that are interested in software. Can you reassign them in the CRM?\"\n",
        "\n",
        "**Expected Steps:**\n",
        "1. Look up Akira's email: `company_directory_find_email_address(name=\"Akira\")`\n",
        "2. Look up John's email: `company_directory_find_email_address(name=\"John\")`  \n",
        "3. Search for leads: `customer_relationship_manager_search_customers(...)`\n",
        "4-6. Update each lead: `customer_relationship_manager_update_customer(...)`\n",
        "\n",
        "## Step 4.1: Stop Current Servers\n",
        "\n",
        "First, stop the example servers by pressing **Ctrl+C** in the terminal running `ng_run`.\n",
        "\n",
        "## Step 4.2: Start Workplace Assistant Servers\n",
        "\n",
        "In your terminal:\n",
        "\n",
        "```bash\n",
        "# Navigate to Gym directory\n",
        "cd /path/to/Gym\n",
        "source .venv/bin/activate\n",
        "\n",
        "# Start Workplace Assistant servers (using vllm_model config)\n",
        "config_paths=\"responses_api_models/vllm_model/configs/vllm_model.yaml,\\\n",
        "resources_servers/workplace_assistant/configs/workplace_assistant.yaml\"\n",
        "ng_run \"+config_paths=[${config_paths}]\"\n",
        "```\n",
        "\n",
        "## Step 4.3: Explore the Workplace Assistant Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "workplace_data_path = GYM_ROOT / \"resources_servers/workplace_assistant/data/train.jsonl\"\n",
        "\n",
        "if workplace_data_path.exists():\n",
        "    print(\"üìã Workplace Assistant training data:\\n\")\n",
        "    \n",
        "    with open(workplace_data_path, 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= 1:  # Show first example\n",
        "                break\n",
        "            data = json.loads(line)\n",
        "            \n",
        "            # Extract user query\n",
        "            inputs = data.get('responses_create_params', {}).get('input', [])\n",
        "            for msg in inputs:\n",
        "                if msg.get('role') == 'user':\n",
        "                    print(f\"User Query: {msg.get('content', 'N/A')[:200]}...\")\n",
        "            \n",
        "            # Show number of tools available\n",
        "            tools = data.get('responses_create_params', {}).get('tools', [])\n",
        "            print(f\"\\nNumber of available tools: {len(tools)}\")\n",
        "            print(\"\\nFirst 5 tools:\")\n",
        "            for tool in tools[:5]:\n",
        "                print(f\"  - {tool.get('name', 'N/A')}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Workplace Assistant data not found locally. Downloading from HuggingFace...\")\n",
        "    \n",
        "    # Download from HuggingFace\n",
        "    import subprocess\n",
        "    \n",
        "    # Create data directory if it doesn't exist\n",
        "    data_dir = GYM_ROOT / \"resources_servers/workplace_assistant/data\"\n",
        "    data_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Download using huggingface_hub\n",
        "    try:\n",
        "        from huggingface_hub import hf_hub_download\n",
        "        \n",
        "        # Download train.jsonl\n",
        "        train_file = hf_hub_download(\n",
        "            repo_id=\"nvidia/Nemotron-RL-agent-workplace_assistant\",\n",
        "            filename=\"train.jsonl\",\n",
        "            repo_type=\"dataset\",\n",
        "            local_dir=str(data_dir),\n",
        "            local_dir_use_symlinks=False\n",
        "        )\n",
        "        print(f\"‚úÖ Downloaded train.jsonl to {data_dir}\")\n",
        "        \n",
        "        # Download test.jsonl if available\n",
        "        try:\n",
        "            test_file = hf_hub_download(\n",
        "                repo_id=\"nvidia/Nemotron-RL-agent-workplace_assistant\",\n",
        "                filename=\"test.jsonl\",\n",
        "                repo_type=\"dataset\",\n",
        "                local_dir=str(data_dir),\n",
        "                local_dir_use_symlinks=False\n",
        "            )\n",
        "            print(f\"‚úÖ Downloaded test.jsonl to {data_dir}\")\n",
        "        except Exception:\n",
        "            print(\"‚ÑπÔ∏è  test.jsonl not found, skipping\")\n",
        "            \n",
        "    except ImportError:\n",
        "        print(\"Installing huggingface_hub...\")\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"huggingface_hub\", \"-q\"])\n",
        "        print(\"Please re-run this cell after installation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4.4: Collect Workplace Assistant Rollouts\n",
        "\n",
        "**‚ö†Ô∏è Important:** Make sure you have started the Workplace Assistant servers (Step 4.2) before running this command!\n",
        "\n",
        "In a **second terminal** (while servers are running in the first), collect rollouts:\n",
        "\n",
        "```bash\n",
        "cd ~/Gym\n",
        "source .venv/bin/activate\n",
        "\n",
        "ng_collect_rollouts +agent_name=workplace_assistant_simple_agent \\\n",
        "    +input_jsonl_fpath=resources_servers/workplace_assistant/data/train.jsonl \\\n",
        "    +output_jsonl_fpath=results/workplace_assistant_rollouts.jsonl \\\n",
        "    +limit=3 \\\n",
        "    +num_samples_in_parallel=2\n",
        "```\n",
        "\n",
        "**Note:** Workplace Assistant tasks take longer due to multi-step tool calling (expect 2-5 minutes).\n",
        "\n",
        "If you see `Missing key workplace_assistant_simple_agent`, it means the Workplace Assistant servers aren't running. Go back to Step 4.2 and start them.\n",
        "\n",
        "---\n",
        "\n",
        "# Part 5: Training with Reinforcement Learning\n",
        "\n",
        "Now that you understand rollout collection, let's explore training options!\n",
        "\n",
        "## Training Pathways\n",
        "\n",
        "### Option A: Quick Start with Unsloth (No Setup Required)\n",
        "\n",
        "**Best for:** Learning, experimentation, small-scale training\n",
        "\n",
        "| Feature | Details |\n",
        "|---------|--------|\n",
        "| **GPU Required** | 1√ó T4 (free on Colab) or 16GB+ local GPU |\n",
        "| **Model** | Qwen-2.5 3B with LoRA |\n",
        "| **Algorithm** | GRPO (Group Relative Policy Optimization) |\n",
        "| **Time** | ~30 minutes |\n",
        "\n",
        "**Run in Google Colab:**\n",
        "https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/nemo_gym_sudoku.ipynb\n",
        "\n",
        "---\n",
        "\n",
        "### Option B: Production Training with NeMo RL\n",
        "\n",
        "**Best for:** Large-scale production training, multi-node clusters\n",
        "\n",
        "| Feature | Details |\n",
        "|---------|--------|\n",
        "| **GPU Required** | 8√ó H100/A100 (80GB+ each) per node |\n",
        "| **Model** | Nemotron Nano 9B v2 |\n",
        "| **Algorithm** | GRPO with tensor parallelism |\n",
        "| **Time** | 3-5 hours |\n",
        "\n",
        "**See the full tutorial:** [NeMo RL GRPO Training](docs/tutorials/nemo-rl-grpo/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NeMo RL Training Setup (Summary)\n",
        "\n",
        "For production training with NeMo RL, you'll need:\n",
        "\n",
        "### 1. Hardware Requirements\n",
        "- **Single-node:** 1 node √ó 8 GPUs (H100/A100 with 80GB+ VRAM)\n",
        "- **Multi-node:** 8+ nodes √ó 8 GPUs each\n",
        "- **RAM:** 64 GB+ per node\n",
        "- **Storage:** 100 GB+ shared filesystem\n",
        "\n",
        "### 2. Software Setup\n",
        "```bash\n",
        "# Use the NeMo RL container\n",
        "CONTAINER_IMAGE_PATH=nvcr.io/nvidia/nemo-rl:v0.4.0.nemotron_3_nano\n",
        "\n",
        "# Clone NeMo RL with Gym submodule\n",
        "git clone https://github.com/NVIDIA-NeMo/RL\n",
        "cd RL\n",
        "git submodule update --init --recursive\n",
        "```\n",
        "\n",
        "### 3. Data Preparation\n",
        "```bash\n",
        "cd 3rdparty/Gym-workspace/Gym\n",
        "uv venv --python 3.12 --allow-existing .venv\n",
        "source .venv/bin/activate\n",
        "uv sync --active --extra dev\n",
        "\n",
        "# Add HuggingFace token\n",
        "echo \"hf_token: {your HF token}\" >> env.yaml\n",
        "\n",
        "# Download and prepare data\n",
        "config_paths=\"responses_api_models/vllm_model/configs/vllm_model_for_training.yaml,\\\n",
        "resources_servers/workplace_assistant/configs/workplace_assistant.yaml\"\n",
        "\n",
        "ng_prepare_data \"+config_paths=[${config_paths}]\" \\\n",
        "    +output_dirpath=data/workplace_assistant \\\n",
        "    +mode=train_preparation \\\n",
        "    +should_download=true \\\n",
        "    +data_source=huggingface\n",
        "```\n",
        "\n",
        "### 4. Training Command\n",
        "```bash\n",
        "CONFIG_PATH=examples/nemo_gym/grpo_workplace_assistant_nemotron_nano_v2_9b.yaml\n",
        "\n",
        "# Download model first\n",
        "HF_HOME=$PWD/.cache/ HF_TOKEN={your HF token} \\\n",
        "    hf download nvidia/NVIDIA-Nemotron-Nano-9B-v2\n",
        "\n",
        "# Run training\n",
        "TORCH_CUDA_ARCH_LIST=\"9.0 10.0\" \\\n",
        "HF_HOME=$PWD/.cache/ \\\n",
        "WANDB_API_KEY={your W&B API key} \\\n",
        "uv run python examples/nemo_gym/run_grpo_nemo_gym.py \\\n",
        "    --config=$CONFIG_PATH \\\n",
        "    ++logger.wandb.project=\"my-nemo-gym-training\" \\\n",
        "    ++grpo.max_num_steps=10\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üéì Summary & Next Steps\n",
        "\n",
        "## What You've Learned\n",
        "\n",
        "1. ‚úÖ **Installation & Setup** - Installed NeMo Gym and configured API keys\n",
        "2. ‚úÖ **Architecture** - Understood the server-based design (Head, Agent, Model, Resources)\n",
        "3. ‚úÖ **Agent Interaction** - Ran a simple agent with tool calling\n",
        "4. ‚úÖ **Rollout Collection** - Generated verified training data\n",
        "5. ‚úÖ **Workplace Assistant** - Explored multi-step agentic environments\n",
        "6. ‚úÖ **Training Options** - Learned about Unsloth and NeMo RL pathways\n",
        "\n",
        "## GPU Requirements Summary\n",
        "\n",
        "| Activity | GPU Required? |\n",
        "|----------|---------------|\n",
        "| NeMo Gym setup & exploration | ‚ùå No |\n",
        "| Rollout collection | ‚ùå No (uses API) |\n",
        "| Unsloth training (Colab) | ‚úÖ 1√ó T4 (free) |\n",
        "| Unsloth training (local) | ‚úÖ 16GB+ VRAM |\n",
        "| NeMo RL training | ‚úÖ 8√ó H100/A100 per node |\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "1. **Build a Custom Environment:**\n",
        "   - Tutorial: `docs/tutorials/creating-resource-server.md`\n",
        "   \n",
        "2. **Try Other Resource Servers:**\n",
        "   - Math: `resources_servers/math_with_judge/`\n",
        "   - Code Generation: `resources_servers/code_gen/`\n",
        "   - Instruction Following: `resources_servers/instruction_following/`\n",
        "\n",
        "3. **Production Training:**\n",
        "   - Full tutorial: `docs/tutorials/nemo-rl-grpo/`\n",
        "   - Multi-node setup: `docs/tutorials/nemo-rl-grpo/multi-node-training.md`\n",
        "\n",
        "## Resources\n",
        "\n",
        "- **Documentation:** https://docs.nvidia.com/nemo/gym/latest/\n",
        "- **GitHub:** https://github.com/NVIDIA-NeMo/Gym\n",
        "- **HuggingFace Datasets:** https://huggingface.co/nvidia (search for Nemotron-RL)\n",
        "- **Report Issues:** https://github.com/NVIDIA-NeMo/Gym/issues\n",
        "\n",
        "---\n",
        "\n",
        "## üßπ Cleanup\n",
        "\n",
        "When you're done, stop the servers by pressing **Ctrl+C** in the terminal running `ng_run`.\n",
        "\n",
        "Optional cleanup commands:\n",
        "```bash\n",
        "# Clean up Ray processes\n",
        "ray stop --force\n",
        "\n",
        "# Remove generated rollouts (if desired)\n",
        "rm -rf results/\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
