{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üèãÔ∏è Getting Started with NeMo Gym\n",
        "\n",
        "**A Complete Step-by-Step Guide for Newcomers**\n",
        "\n",
        "---\n",
        "\n",
        "NeMo Gym is a library for building reinforcement learning (RL) training environments for large language models (LLMs). It provides infrastructure to develop environments, scale rollout collection, and integrate seamlessly with your preferred training framework.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "This notebook covers:\n",
        "\n",
        "1. **üîß Environment Setup** - Install NeMo Gym and configure NVIDIA API keys\n",
        "2. **üöÄ Quick Start** - Start servers and interact with your first agent (powered by [Nemotron Super NIM](https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1))\n",
        "3. **üìä Rollout Collection** - Generate verified training data\n",
        "4. **üè¢ Workplace Assistant Tutorial** - Explore multi-step tool calling\n",
        "5. **üí™ Training with RL** - Understand GPU requirements and training options\n",
        "\n",
        "---\n",
        "\n",
        "## üíª Hardware & GPU Requirements\n",
        "\n",
        "| Component | NeMo Gym Library | RL Training (Optional) |\n",
        "|-----------|------------------|------------------------|\n",
        "| **GPU** | ‚ùå Not required | ‚úÖ Required |\n",
        "| **CPU** | Any modern x86_64 or ARM64 | Any modern x86_64 |\n",
        "| **RAM** | 8 GB minimum (16 GB+ recommended) | 64 GB+ per node |\n",
        "| **Storage** | 2-5 GB | 100 GB+ (shared filesystem) |\n",
        "\n",
        "### Training GPU Requirements\n",
        "\n",
        "| Training Framework | GPU Requirements |\n",
        "|-------------------|------------------|\n",
        "| **Unsloth (Colab)** | 1√ó T4 GPU (16GB VRAM) - Free tier available |\n",
        "| **Unsloth (Local)** | 1√ó GPU with 16GB+ VRAM |\n",
        "| **NeMo RL (Single-node)** | 8√ó NVIDIA GPUs (80GB+ each, e.g., H100/A100) |\n",
        "| **NeMo RL (Multi-node)** | 8+ nodes √ó 8 GPUs (80GB+ each) |\n",
        "\n",
        "**Note:** This notebook focuses on NeMo Gym setup and exploration, which does NOT require a GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 1: Environment Setup\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Before starting, ensure you have:\n",
        "- **Git** installed\n",
        "- **Python 3.12+** installed\n",
        "- **NVIDIA API key** from [NVIDIA Build](https://build.nvidia.com/) (free tier available)\n",
        "\n",
        "## Step 1.1: Verify Python Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "print(f\"Python version: {sys.version}\")\n",
        "major, minor = sys.version_info[:2]\n",
        "\n",
        "if major >= 3 and minor >= 12:\n",
        "    print(\"‚úÖ Python version is compatible (3.12+)\")\n",
        "else:\n",
        "    print(\"‚ùå Please upgrade to Python 3.12 or higher\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.2: Clone the Repository (If Not Already Done)\n",
        "\n",
        "If you're running this notebook outside the Gym repository, run these commands in your terminal:\n",
        "\n",
        "```bash\n",
        "# Clone the repository\n",
        "git clone git@github.com:NVIDIA-NeMo/Gym.git\n",
        "cd Gym\n",
        "\n",
        "# Install UV (Python package manager)\n",
        "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "source $HOME/.local/bin/env\n",
        "\n",
        "# Create virtual environment\n",
        "uv venv --python 3.12\n",
        "source .venv/bin/activate\n",
        "\n",
        "# Install NeMo Gym\n",
        "uv sync --extra dev --group docs\n",
        "```\n",
        "\n",
        "## Step 1.3: Verify NeMo Gym Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import nemo_gym\n",
        "    print(f\"‚úÖ NeMo Gym imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå NeMo Gym not installed. Please run: uv sync --extra dev --group docs\")\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.4: Configure Your NVIDIA API Key\n",
        "\n",
        "Create an `env.yaml` file with your API credentials. This file keeps secrets out of version control.\n",
        "\n",
        "We'll use **NVIDIA's Nemotron Super NIM** - a powerful 49B parameter model optimized for reasoning, tool calling, and instruction following with 128K context length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Get the Gym project root directory\n",
        "# Adjust this path if running from a different location\n",
        "GYM_ROOT = Path(os.getcwd())\n",
        "if not (GYM_ROOT / \"nemo_gym\").exists():\n",
        "    # Try parent directory\n",
        "    GYM_ROOT = GYM_ROOT.parent\n",
        "    if not (GYM_ROOT / \"nemo_gym\").exists():\n",
        "        print(\"‚ö†Ô∏è  Cannot find Gym root directory. Please run this notebook from the Gym directory.\")\n",
        "\n",
        "ENV_YAML_PATH = GYM_ROOT / \"env.yaml\"\n",
        "print(f\"üìÅ Gym root directory: {GYM_ROOT}\")\n",
        "print(f\"üìÑ env.yaml path: {ENV_YAML_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if env.yaml already exists\n",
        "if ENV_YAML_PATH.exists():\n",
        "    print(\"‚úÖ env.yaml already exists\")\n",
        "    print(\"\\nCurrent content (API key masked):\")\n",
        "    content = ENV_YAML_PATH.read_text()\n",
        "    for line in content.split('\\n'):\n",
        "        if 'api_key' in line.lower():\n",
        "            key_part = line.split(':')[0]\n",
        "            print(f\"{key_part}: nvapi-****...****\")\n",
        "        else:\n",
        "            print(line)\n",
        "else:\n",
        "    print(\"‚ùå env.yaml not found. Please create it in the next step.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create or Update env.yaml\n",
        "\n",
        "**Option A:** Run the cell below and replace `nvapi-...` with your actual NVIDIA API key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚ö†Ô∏è REPLACE with your actual NVIDIA API key\n",
        "NVIDIA_API_KEY = \"nvapi-...\"  # <-- Replace this!\n",
        "POLICY_MODEL = \"nvidia/llama-3.3-nemotron-super-49b-v1\"  # Nemotron Super NIM\n",
        "\n",
        "if NVIDIA_API_KEY == \"nvapi-...\":\n",
        "    print(\"‚ö†Ô∏è  Please replace 'nvapi-...' with your actual NVIDIA API key\")\n",
        "    print(\"\\nYou can get your API key from: https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1\")\n",
        "else:\n",
        "    env_yaml_content = f\"\"\"policy_base_url: https://integrate.api.nvidia.com/v1\n",
        "policy_api_key: {NVIDIA_API_KEY}\n",
        "policy_model_name: {POLICY_MODEL}\n",
        "\"\"\"\n",
        "    \n",
        "    ENV_YAML_PATH.write_text(env_yaml_content)\n",
        "    print(\"‚úÖ env.yaml created successfully!\")\n",
        "    print(f\"üìç Location: {ENV_YAML_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Option B:** Create the file manually via terminal:\n",
        "\n",
        "```bash\n",
        "echo \"policy_base_url: https://integrate.api.nvidia.com/v1\n",
        "policy_api_key: nvapi-your-nvidia-api-key\n",
        "policy_model_name: nvidia/llama-3.3-nemotron-super-49b-v1\" > env.yaml\n",
        "```\n",
        "\n",
        "## Step 1.5: Validate API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate the API key before proceeding\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "    from nemo_gym.global_config import get_global_config_dict\n",
        "    \n",
        "    global_config = get_global_config_dict()\n",
        "    \n",
        "    client = OpenAI(\n",
        "        api_key=global_config['policy_api_key'],\n",
        "        base_url=global_config['policy_base_url']\n",
        "    )\n",
        "    \n",
        "    # Test with a simple request\n",
        "    response = client.chat.completions.create(\n",
        "        model=global_config['policy_model_name'],\n",
        "        messages=[{'role': 'user', 'content': 'Say hello'}],\n",
        "        max_tokens=10\n",
        "    )\n",
        "    \n",
        "    print(\"‚úÖ API key validated successfully!\")\n",
        "    print(f\"Model: {global_config['policy_model_name']}\")\n",
        "    print(f\"Response: {response.choices[0].message.content}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå API validation failed: {e}\")\n",
        "    print(\"\\nTroubleshooting:\")\n",
        "    print(\"- Check your NVIDIA API key is correct (should start with 'nvapi-')\")\n",
        "    print(\"- Get a free API key from: https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1\")\n",
        "    print(\"- Ensure env.yaml is in the Gym root directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 2: Quick Start - Your First Agent\n",
        "\n",
        "Now let's start the NeMo Gym servers and interact with an agent!\n",
        "\n",
        "## Understanding the Architecture\n",
        "\n",
        "NeMo Gym uses a server-based architecture:\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ   Head Server    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Agent Server    ‚îÇ\n",
        "‚îÇ   (port 11000)   ‚îÇ     ‚îÇ (auto-assigned)  ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                  ‚îÇ\n",
        "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚ñº                           ‚ñº\n",
        "           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "           ‚îÇ Model Server   ‚îÇ         ‚îÇResources Server‚îÇ\n",
        "           ‚îÇ (LLM Inference)‚îÇ         ‚îÇ (Tools/Verify) ‚îÇ\n",
        "           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "## Step 2.1: Start the Servers\n",
        "\n",
        "**‚ö†Ô∏è Important:** Run this in a **separate terminal** (not in this notebook):\n",
        "\n",
        "```bash\n",
        "# Navigate to Gym directory\n",
        "cd /path/to/Gym\n",
        "\n",
        "# Activate virtual environment\n",
        "source .venv/bin/activate\n",
        "\n",
        "# Start servers\n",
        "config_paths=\"resources_servers/example_single_tool_call/configs/example_single_tool_call.yaml,\\\n",
        "responses_api_models/openai_model/configs/openai_model.yaml\"\n",
        "ng_run \"+config_paths=[${config_paths}]\"\n",
        "```\n",
        "\n",
        "**Expected output:**\n",
        "```\n",
        "INFO:     Started server process [12345]\n",
        "INFO:     Uvicorn running on http://127.0.0.1:11000 (Press CTRL+C to quit)\n",
        "INFO:     Started server process [12346]  \n",
        "INFO:     Uvicorn running on http://127.0.0.1:62920 (Press CTRL+C to quit)\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.2: Wait for Servers and Verify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "def check_servers(max_attempts=10, delay=2):\n",
        "    \"\"\"Check if NeMo Gym servers are running.\"\"\"\n",
        "    for attempt in range(max_attempts):\n",
        "        try:\n",
        "            response = requests.get(\"http://localhost:11000/server_instances\", timeout=5)\n",
        "            if response.status_code == 200:\n",
        "                print(\"‚úÖ Servers are running!\")\n",
        "                print(\"\\nRegistered servers:\")\n",
        "                for server in response.json():\n",
        "                    print(f\"  - {server['name']}: {server['host']}:{server['port']}\")\n",
        "                return True\n",
        "        except requests.exceptions.ConnectionError:\n",
        "            print(f\"‚è≥ Waiting for servers... (attempt {attempt + 1}/{max_attempts})\")\n",
        "            time.sleep(delay)\n",
        "    \n",
        "    print(\"‚ùå Servers not responding. Please start them with ng_run.\")\n",
        "    return False\n",
        "\n",
        "# Check if servers are running\n",
        "servers_ok = check_servers()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.3: Interact with the Simple Agent\n",
        "\n",
        "If the servers are running, let's interact with the agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import json\n",
        "\n",
        "if servers_ok:\n",
        "    print(\"ü§ñ Running simple agent client...\\n\")\n",
        "    \n",
        "    # Run the client script\n",
        "    result = subprocess.run(\n",
        "        [\"python\", \"responses_api_agents/simple_agent/client.py\"],\n",
        "        cwd=str(GYM_ROOT),\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "    \n",
        "    if result.returncode == 0:\n",
        "        print(\"‚úÖ Agent interaction successful!\")\n",
        "        print(\"\\nüìã Response:\")\n",
        "        try:\n",
        "            # Pretty print the JSON response\n",
        "            output = json.loads(result.stdout)\n",
        "            print(json.dumps(output, indent=2))\n",
        "        except json.JSONDecodeError:\n",
        "            print(result.stdout)\n",
        "    else:\n",
        "        print(f\"‚ùå Error: {result.stderr}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Please start the servers first (see Step 2.1)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What Just Happened?\n",
        "\n",
        "1. **User Query:** \"What's the weather in San Francisco?\"\n",
        "2. **Agent Action:** Called the `get_weather` tool with `{\"city\": \"San Francisco\"}`\n",
        "3. **Tool Response:** Returned weather data\n",
        "4. **Final Response:** Agent provided a natural language answer\n",
        "\n",
        "This demonstrates the core loop of NeMo Gym: **Query ‚Üí Tool Calls ‚Üí Verification ‚Üí Response**\n",
        "\n",
        "---\n",
        "\n",
        "# Part 3: Rollout Collection\n",
        "\n",
        "Rollouts are complete records of task executions with verification scores. They're the training data for RL!\n",
        "\n",
        "## Step 3.1: Inspect the Example Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "example_data_path = GYM_ROOT / \"resources_servers/example_single_tool_call/data/example.jsonl\"\n",
        "\n",
        "print(\"üìÑ Example dataset content:\\n\")\n",
        "\n",
        "with open(example_data_path, 'r') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= 2:  # Show first 2 examples\n",
        "            break\n",
        "        data = json.loads(line)\n",
        "        print(f\"Example {i+1}:\")\n",
        "        print(json.dumps(data, indent=2))\n",
        "        print(\"\\n\" + \"=\"*60 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3.2: Collect Rollouts\n",
        "\n",
        "Run this in your **second terminal** (with servers running in the first):\n",
        "\n",
        "```bash\n",
        "# Activate environment\n",
        "source .venv/bin/activate\n",
        "\n",
        "# Collect rollouts\n",
        "ng_collect_rollouts +agent_name=example_single_tool_call_simple_agent \\\n",
        "    +input_jsonl_fpath=resources_servers/example_single_tool_call/data/example.jsonl \\\n",
        "    +output_jsonl_fpath=results/example_single_tool_call_rollouts.jsonl \\\n",
        "    +limit=5 \\\n",
        "    +num_repeats=2 \\\n",
        "    +num_samples_in_parallel=3\n",
        "```\n",
        "\n",
        "### Parameters Explained:\n",
        "\n",
        "| Parameter | Description |\n",
        "|-----------|-------------|\n",
        "| `+agent_name` | Which agent to use |\n",
        "| `+input_jsonl_fpath` | Path to input dataset |\n",
        "| `+output_jsonl_fpath` | Path to save rollouts |\n",
        "| `+limit` | Max examples to process |\n",
        "| `+num_repeats` | Rollouts per example |\n",
        "| `+num_samples_in_parallel` | Concurrent requests |\n",
        "\n",
        "## Step 3.3: View Collected Rollouts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rollouts_path = GYM_ROOT / \"results/example_single_tool_call_rollouts.jsonl\"\n",
        "\n",
        "if rollouts_path.exists():\n",
        "    print(\"üìä Collected rollouts:\\n\")\n",
        "    \n",
        "    with open(rollouts_path, 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= 2:  # Show first 2 rollouts\n",
        "                break\n",
        "            rollout = json.loads(line)\n",
        "            print(f\"Rollout {i+1}:\")\n",
        "            print(f\"  Reward: {rollout.get('reward', 'N/A')}\")\n",
        "            print(f\"  Keys: {list(rollout.keys())}\")\n",
        "            print()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Rollouts file not found. Please run ng_collect_rollouts first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3.4: Launch the Rollout Viewer (Optional)\n",
        "\n",
        "For a visual interface to explore rollouts:\n",
        "\n",
        "```bash\n",
        "ng_viewer +jsonl_fpath=results/example_single_tool_call_rollouts.jsonl\n",
        "```\n",
        "\n",
        "Then visit: http://127.0.0.1:7860\n",
        "\n",
        "---\n",
        "\n",
        "# Part 4: Workplace Assistant Tutorial\n",
        "\n",
        "Now let's explore a more complex environment: **Workplace Assistant**. This is a multi-step agentic tool-use environment that tests a model's ability to execute business tasks.\n",
        "\n",
        "## About Workplace Assistant\n",
        "\n",
        "### Features:\n",
        "- **5 Databases:** Email, Calendar, Analytics, Project Management, CRM\n",
        "- **27 Tools:** Distributed across databases for various operations\n",
        "- **690+ Tasks:** Common business activities (emails, meetings, project management)\n",
        "- **Multi-step reasoning:** Tasks require 1-6 tool calls in sequence\n",
        "\n",
        "### Example Multi-Step Task:\n",
        "\n",
        "**User:** \"John is taking over all of Akira's leads that are interested in software. Can you reassign them in the CRM?\"\n",
        "\n",
        "**Expected Steps:**\n",
        "1. Look up Akira's email: `company_directory_find_email_address(name=\"Akira\")`\n",
        "2. Look up John's email: `company_directory_find_email_address(name=\"John\")`  \n",
        "3. Search for leads: `customer_relationship_manager_search_customers(...)`\n",
        "4-6. Update each lead: `customer_relationship_manager_update_customer(...)`\n",
        "\n",
        "## Step 4.1: Stop Current Servers\n",
        "\n",
        "First, stop the example servers by pressing **Ctrl+C** in the terminal running `ng_run`.\n",
        "\n",
        "## Step 4.2: Start Workplace Assistant Servers\n",
        "\n",
        "In your terminal:\n",
        "\n",
        "```bash\n",
        "# Navigate to Gym directory\n",
        "cd /path/to/Gym\n",
        "source .venv/bin/activate\n",
        "\n",
        "# Start Workplace Assistant servers\n",
        "config_paths=\"responses_api_models/openai_model/configs/openai_model.yaml,\\\n",
        "resources_servers/workplace_assistant/configs/workplace_assistant.yaml\"\n",
        "ng_run \"+config_paths=[${config_paths}]\"\n",
        "```\n",
        "\n",
        "## Step 4.3: Explore the Workplace Assistant Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "workplace_data_path = GYM_ROOT / \"resources_servers/workplace_assistant/data/train.jsonl\"\n",
        "\n",
        "if workplace_data_path.exists():\n",
        "    print(\"üìã Workplace Assistant training data:\\n\")\n",
        "    \n",
        "    with open(workplace_data_path, 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= 1:  # Show first example\n",
        "                break\n",
        "            data = json.loads(line)\n",
        "            \n",
        "            # Extract user query\n",
        "            inputs = data.get('responses_create_params', {}).get('input', [])\n",
        "            for msg in inputs:\n",
        "                if msg.get('role') == 'user':\n",
        "                    print(f\"User Query: {msg.get('content', 'N/A')[:200]}...\")\n",
        "            \n",
        "            # Show number of tools available\n",
        "            tools = data.get('responses_create_params', {}).get('tools', [])\n",
        "            print(f\"\\nNumber of available tools: {len(tools)}\")\n",
        "            print(\"\\nFirst 5 tools:\")\n",
        "            for tool in tools[:5]:\n",
        "                print(f\"  - {tool.get('name', 'N/A')}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Workplace Assistant data not found locally.\")\n",
        "    print(\"\\nYou can download it from HuggingFace:\")\n",
        "    print(\"https://huggingface.co/datasets/nvidia/Nemotron-RL-agent-workplace_assistant\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4.4: Collect Workplace Assistant Rollouts\n",
        "\n",
        "With servers running, collect rollouts:\n",
        "\n",
        "```bash\n",
        "ng_collect_rollouts +agent_name=workplace_assistant_simple_agent \\\n",
        "    +input_jsonl_fpath=resources_servers/workplace_assistant/data/train.jsonl \\\n",
        "    +output_jsonl_fpath=results/workplace_assistant_rollouts.jsonl \\\n",
        "    +limit=3 \\\n",
        "    +num_samples_in_parallel=2\n",
        "```\n",
        "\n",
        "**Note:** Workplace Assistant tasks take longer due to multi-step tool calling.\n",
        "\n",
        "---\n",
        "\n",
        "# Part 5: Training with Reinforcement Learning\n",
        "\n",
        "Now that you understand rollout collection, let's explore training options!\n",
        "\n",
        "## Training Pathways\n",
        "\n",
        "### Option A: Quick Start with Unsloth (No Setup Required)\n",
        "\n",
        "**Best for:** Learning, experimentation, small-scale training\n",
        "\n",
        "| Feature | Details |\n",
        "|---------|--------|\n",
        "| **GPU Required** | 1√ó T4 (free on Colab) or 16GB+ local GPU |\n",
        "| **Model** | Qwen-2.5 3B with LoRA |\n",
        "| **Algorithm** | GRPO (Group Relative Policy Optimization) |\n",
        "| **Time** | ~30 minutes |\n",
        "\n",
        "**Run in Google Colab:**\n",
        "https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/nemo_gym_sudoku.ipynb\n",
        "\n",
        "---\n",
        "\n",
        "### Option B: Production Training with NeMo RL\n",
        "\n",
        "**Best for:** Large-scale production training, multi-node clusters\n",
        "\n",
        "| Feature | Details |\n",
        "|---------|--------|\n",
        "| **GPU Required** | 8√ó H100/A100 (80GB+ each) per node |\n",
        "| **Model** | Nemotron Nano 9B v2 |\n",
        "| **Algorithm** | GRPO with tensor parallelism |\n",
        "| **Time** | 3-5 hours |\n",
        "\n",
        "**See the full tutorial:** [NeMo RL GRPO Training](docs/tutorials/nemo-rl-grpo/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NeMo RL Training Setup (Summary)\n",
        "\n",
        "For production training with NeMo RL, you'll need:\n",
        "\n",
        "### 1. Hardware Requirements\n",
        "- **Single-node:** 1 node √ó 8 GPUs (H100/A100 with 80GB+ VRAM)\n",
        "- **Multi-node:** 8+ nodes √ó 8 GPUs each\n",
        "- **RAM:** 64 GB+ per node\n",
        "- **Storage:** 100 GB+ shared filesystem\n",
        "\n",
        "### 2. Software Setup\n",
        "```bash\n",
        "# Use the NeMo RL container\n",
        "CONTAINER_IMAGE_PATH=nvcr.io/nvidia/nemo-rl:v0.4.0.nemotron_3_nano\n",
        "\n",
        "# Clone NeMo RL with Gym submodule\n",
        "git clone https://github.com/NVIDIA-NeMo/RL\n",
        "cd RL\n",
        "git submodule update --init --recursive\n",
        "```\n",
        "\n",
        "### 3. Data Preparation\n",
        "```bash\n",
        "cd 3rdparty/Gym-workspace/Gym\n",
        "uv venv --python 3.12 --allow-existing .venv\n",
        "source .venv/bin/activate\n",
        "uv sync --active --extra dev\n",
        "\n",
        "# Add HuggingFace token\n",
        "echo \"hf_token: {your HF token}\" >> env.yaml\n",
        "\n",
        "# Download and prepare data\n",
        "config_paths=\"responses_api_models/vllm_model/configs/vllm_model_for_training.yaml,\\\n",
        "resources_servers/workplace_assistant/configs/workplace_assistant.yaml\"\n",
        "\n",
        "ng_prepare_data \"+config_paths=[${config_paths}]\" \\\n",
        "    +output_dirpath=data/workplace_assistant \\\n",
        "    +mode=train_preparation \\\n",
        "    +should_download=true \\\n",
        "    +data_source=huggingface\n",
        "```\n",
        "\n",
        "### 4. Training Command\n",
        "```bash\n",
        "CONFIG_PATH=examples/nemo_gym/grpo_workplace_assistant_nemotron_nano_v2_9b.yaml\n",
        "\n",
        "# Download model first\n",
        "HF_HOME=$PWD/.cache/ HF_TOKEN={your HF token} \\\n",
        "    hf download nvidia/NVIDIA-Nemotron-Nano-9B-v2\n",
        "\n",
        "# Run training\n",
        "TORCH_CUDA_ARCH_LIST=\"9.0 10.0\" \\\n",
        "HF_HOME=$PWD/.cache/ \\\n",
        "WANDB_API_KEY={your W&B API key} \\\n",
        "uv run python examples/nemo_gym/run_grpo_nemo_gym.py \\\n",
        "    --config=$CONFIG_PATH \\\n",
        "    ++logger.wandb.project=\"my-nemo-gym-training\" \\\n",
        "    ++grpo.max_num_steps=10\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üéì Summary & Next Steps\n",
        "\n",
        "## What You've Learned\n",
        "\n",
        "1. ‚úÖ **Installation & Setup** - Installed NeMo Gym and configured API keys\n",
        "2. ‚úÖ **Architecture** - Understood the server-based design (Head, Agent, Model, Resources)\n",
        "3. ‚úÖ **Agent Interaction** - Ran a simple agent with tool calling\n",
        "4. ‚úÖ **Rollout Collection** - Generated verified training data\n",
        "5. ‚úÖ **Workplace Assistant** - Explored multi-step agentic environments\n",
        "6. ‚úÖ **Training Options** - Learned about Unsloth and NeMo RL pathways\n",
        "\n",
        "## GPU Requirements Summary\n",
        "\n",
        "| Activity | GPU Required? |\n",
        "|----------|---------------|\n",
        "| NeMo Gym setup & exploration | ‚ùå No |\n",
        "| Rollout collection | ‚ùå No (uses API) |\n",
        "| Unsloth training (Colab) | ‚úÖ 1√ó T4 (free) |\n",
        "| Unsloth training (local) | ‚úÖ 16GB+ VRAM |\n",
        "| NeMo RL training | ‚úÖ 8√ó H100/A100 per node |\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "1. **Build a Custom Environment:**\n",
        "   - Tutorial: `docs/tutorials/creating-resource-server.md`\n",
        "   \n",
        "2. **Try Other Resource Servers:**\n",
        "   - Math: `resources_servers/math_with_judge/`\n",
        "   - Code Generation: `resources_servers/code_gen/`\n",
        "   - Instruction Following: `resources_servers/instruction_following/`\n",
        "\n",
        "3. **Production Training:**\n",
        "   - Full tutorial: `docs/tutorials/nemo-rl-grpo/`\n",
        "   - Multi-node setup: `docs/tutorials/nemo-rl-grpo/multi-node-training.md`\n",
        "\n",
        "## Resources\n",
        "\n",
        "- **Documentation:** https://docs.nvidia.com/nemo/gym/latest/\n",
        "- **GitHub:** https://github.com/NVIDIA-NeMo/Gym\n",
        "- **HuggingFace Datasets:** https://huggingface.co/nvidia (search for Nemotron-RL)\n",
        "- **Report Issues:** https://github.com/NVIDIA-NeMo/Gym/issues\n",
        "\n",
        "---\n",
        "\n",
        "## üßπ Cleanup\n",
        "\n",
        "When you're done, stop the servers by pressing **Ctrl+C** in the terminal running `ng_run`.\n",
        "\n",
        "Optional cleanup commands:\n",
        "```bash\n",
        "# Clean up Ray processes\n",
        "ray stop --force\n",
        "\n",
        "# Remove generated rollouts (if desired)\n",
        "rm -rf results/\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
